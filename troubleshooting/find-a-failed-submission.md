---
category: Runner
expires: 2020-07-19
---

## Delayed Job Failures

Form Builder submissions are put onto a queue to be processed by the Submitter. Sometimes these can fail. They trigger a `FailedDelayedJob` alert which is sent to the #form-builder-alerts channel.

### Find the correct environment

Sometimes the environment the alert ocurred in does not get outputted to Slack. You can check the Form Builder [Grafana dashboard](https://grafana.cloud-platform.service.justice.gov.uk/d/-hXgWMWWk/form-builder?orgId=1) to see where it occurred. Failed Submitter Delayed Jobs is the top left box. Toggle the `platform_env` and `deployment_env` to move between environments.

### Locate a Submitter API pod

Once you know which environment you need to check you can log into the required submitter api container:
~~~~~~~~
kubectl get pods -n formbuilder-platform-<platform_env>-<deployment_env>
~~~~~~~~
E.g
~~~~~~~~
kubectl get pods -n formbuilder-platform-test-dev
~~~~~~~~
### Check the logs

Get the submitter api pod name from the list generated by the above commadn and then take a look at the logs from around the time of the alert:
~~~~~~~~
kubectl logs -n formbuilder-platform-live-dev fb-submitter-api-live-dev-<identifier>
~~~~~~~~
The `identifier` is generated when the pod is deployed so is different each time. The logs should hopefully give you an idea as to what happened.

### Check failure message in the Delayed Job

You can also log into one of the Submitter API pods and take a look at the error message attached to the failed Delayed Job
~~~~~~~~
kubectl exec -ti -n formbuilder-platform-test-dev fb-submitter-api-test-dev-<identifier>  -- bash
~~~~~~~~
Then run a Rails console: 
~~~~~~~~
bundle exec rails c
~~~~~~~~

You can see the jobs that are currently stuck on the queue:

~~~~~~~~
Delayed::Job.all
~~~~~~~~

or if to narrow it down to just todays failed jobs:

~~~~~~~~
Delayed::Job.where(created_at: Time.zone.now.beginning_of_day..Time.zone.now.end_of_day)
~~~~~~~~

The output will show you the number of retries and also show the error message generated when the job failed.

You can also see the stack trace of the error:

~~~~~~~~
Delayed::Job.last.last_error
~~~~~~~~

### Replaying failed jobs

Once you are happy that it is ok to replay the failed job you will need to re-encrypt the payload of the Submission related to the Delayed Job. First get the Submission ID. Why the re-encryption is required is a good question. There seems to be some connection between when the payload is encrypted and the JWT skew validation that happens between the platform apps. Needs further investigating.

For example if the Delayed Job you need to replay is the last one:

~~~~~~~~
submission_id = Delayed::Job.last.handler
~~~~~~~~

~~~~~~~~
submission = Submission.find_by_id(submission_id)
~~~~~~~~

The payload is encrypted. Unfortunately you will need to decrypt it before you can re-encrypt it again:

~~~~~~~~
submission.update(payload: EncryptionService.new.encrypt(submission.decrypted_payload))
~~~~~~~~

Then you can update the `run_at` parameter of required Delayed Job so that it runs again when you want it to. In this example we just used 10 seconds as an arbitrary time.

~~~~~~~~
Delayed::Job.last.update(run_at: Time.now + 10.seconds)
~~~~~~~~

All being well you will no longer see that Delayed Job in the queue any longer. Great success!
